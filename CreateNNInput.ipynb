{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15ebc57f-dc88-4fee-b522-1ab3e75955d7",
   "metadata": {},
   "source": [
    "# Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d966e0b6-440f-492a-985a-1a2ee774cd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ddf26d-7e65-4df1-a7d7-b4df98a22792",
   "metadata": {},
   "source": [
    "# Relhum conversion functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58a08c34-4203-4b7e-9f72-6ee3c6de3fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliq(T):\n",
    "    a_liq = np.float32(np.array([-0.976195544e-15,-0.952447341e-13,\\\n",
    "                                 0.640689451e-10,\\\n",
    "                      0.206739458e-7,0.302950461e-5,0.264847430e-3,\\\n",
    "                      0.142986287e-1,0.443987641,6.11239921]));\n",
    "    c_liq = np.float32(-80.0)\n",
    "    T0 = np.float32(273.16)\n",
    "    return np.float32(100.0)*np.polyval(a_liq,np.maximum(c_liq,T-T0))\n",
    "\n",
    "def eice(T):\n",
    "    a_ice = np.float32(np.array([0.252751365e-14,0.146898966e-11,0.385852041e-9,\\\n",
    "                      0.602588177e-7,0.615021634e-5,0.420895665e-3,\\\n",
    "                      0.188439774e-1,0.503160820,6.11147274]));\n",
    "    c_ice = np.float32(np.array([273.15,185,-100,0.00763685,0.000151069,7.48215e-07]))\n",
    "    T0 = np.float32(273.16)\n",
    "    return np.where(T>c_ice[0],eliq(T),\\\n",
    "                   np.where(T<=c_ice[1],np.float32(100.0)*(c_ice[3]+np.maximum(c_ice[2],T-T0)*\\\n",
    "                   (c_ice[4]+np.maximum(c_ice[2],T-T0)*c_ice[5])),\\\n",
    "                           np.float32(100.0)*np.polyval(a_ice,T-T0)))\n",
    "\n",
    "def esat(T):\n",
    "    T0 = np.float32(273.16)\n",
    "    T00 = np.float32(253.16)\n",
    "    omtmp = (T-T00)/(T0-T00)\n",
    "    omega = np.maximum(np.float32(0.0),np.minimum(np.float32(1.0),omtmp))\n",
    "    return np.where(T>T0,eliq(T),np.where(T<T00,eice(T),(omega*eliq(T)+(1-omega)*eice(T))))\n",
    "\n",
    "def RH(T,qv,P0,PS,hyam,hybm):\n",
    "    R = np.float32(287.0)\n",
    "    Rv = np.float32(461.0)\n",
    "    p = P0 * hyam + PS[:, None] * hybm # Total pressure (Pa)\n",
    "    \n",
    "    T = np.float32(T)\n",
    "    qv = np.float32(qv)\n",
    "    p = np.float32(p)\n",
    "    \n",
    "    return Rv*p*qv/(R*esat(T))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97a600d-245a-4016-b25f-3c6495c0973c",
   "metadata": {},
   "source": [
    "# Data processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "545f3bc4-43a9-46d2-88d5-0b29433905a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_month(month):\n",
    "    datasets = !ls\n",
    "    n = str(month)\n",
    "    datasets = [x for x in datasets if \"h1.0000-\" + n.zfill(2) in x]\n",
    "    return xr.open_mfdataset(datasets)\n",
    "\n",
    "def make_nninput(spData, family, save_diagnostics = False, full_run = False):\n",
    "    nntbp = np.float32(spData[\"NNTBP\"].values)\n",
    "    nnqbp = np.float32(spData[\"NNQBP\"].values)\n",
    "    p0 = np.float32(spData[\"P0\"].values)\n",
    "    ps = np.float32(spData[\"NNPS\"].values)\n",
    "    hyam = np.float32(spData[\"hyam\"].values)\n",
    "    hybm = np.float32(spData[\"hybm\"].values)\n",
    "    relhum = np.float32(spData[\"RELHUM\"].values)\n",
    "    tphystnd = np.float32(spData[\"TPHYSTND\"].values)\n",
    "    phq = np.float32(spData[\"PHQ\"].values)\n",
    "\n",
    "    p0 = np.float32(np.array(list(set(p0))))\n",
    "    print(\"loaded in data\")\n",
    "    newhum = np.float32(np.zeros((spData[\"time\"].shape[0],\\\n",
    "                                  spData[\"lev\"].shape[0], \\\n",
    "                                  spData[\"lat\"].shape[0], \\\n",
    "                                  spData[\"lon\"].shape[0])))\n",
    "    lats = spData[\"lat\"]\n",
    "    lons = spData[\"lon\"]\n",
    "    print(\"starting for loop\")\n",
    "    for i in tqdm(range(len(lats))):\n",
    "        for j in range(len(lons)):\n",
    "            latIndex = i\n",
    "            lonIndex = j\n",
    "            R = np.float32(287.0)\n",
    "            Rv = np.float32(461.0)\n",
    "            p = np.float32(p0 * hyam + ps[:, None, latIndex, lonIndex] * hybm) # Total pressure (Pa)\n",
    "            T = np.float32(nntbp[:, :, latIndex, lonIndex])\n",
    "            qv = np.float32(nnqbp[:, :, latIndex, lonIndex])\n",
    "            p = np.float32(p)\n",
    "            newhum[:,:, latIndex, lonIndex] = np.float32(Rv*p*qv/(R*esat(T)))\n",
    "    \n",
    "    nntbp = np.float32(np.moveaxis(nntbp[1:,:,:,:],0,1))\n",
    "    print(\"nntbp\")\n",
    "    print(nntbp.shape)\n",
    "    \n",
    "    nnqbp = np.float32(np.moveaxis(nnqbp[1:,:,:,:],0,1))\n",
    "    print(\"nnqbp\")\n",
    "    print(nnqbp.shape)\n",
    "    \n",
    "    lhflx = np.float32(spData[\"LHFLX\"].values[np.newaxis,:-1,:,:])\n",
    "    print(\"lhflx\")\n",
    "    print(lhflx.shape)\n",
    "    \n",
    "    shflx = np.float32(spData[\"SHFLX\"].values[np.newaxis,:-1,:,:])\n",
    "    print(\"shflx\")\n",
    "    print(shflx.shape)\n",
    "    \n",
    "    ps = np.float32(spData[\"NNPS\"].values[np.newaxis,1:,:,:])\n",
    "    print(\"ps\")\n",
    "    print(ps.shape)\n",
    "    \n",
    "    solin = np.float32(spData[\"SOLIN\"].values[np.newaxis,1:,:,:])\n",
    "    print(\"solin\")\n",
    "    print(solin.shape)\n",
    "    \n",
    "    newhum = np.float32(np.moveaxis(newhum[1:,:,:,:],0,1))\n",
    "    print(\"newhum\")\n",
    "    print(newhum.shape)\n",
    "    \n",
    "    oldhum = np.float32(np.moveaxis(relhum[1:,:,:,:],0,1))\n",
    "    print(\"oldhum\")\n",
    "    print(oldhum.shape)\n",
    "    \n",
    "    tphystnd = np.float32(np.moveaxis(tphystnd[1:,:,:,:],0,1))\n",
    "    print(\"tphystnd\")\n",
    "    print(tphystnd.shape)\n",
    "    \n",
    "    phq = np.float32(np.moveaxis(phq[1:,:,:,:],0,1))\n",
    "    print(\"phq\")\n",
    "    print(phq.shape)\n",
    "        \n",
    "    if family == \"specific\":\n",
    "        nnInput = np.float32(np.concatenate((nntbp, \\\n",
    "                                             nnqbp, \\\n",
    "                                             ps, \\\n",
    "                                             solin, \\\n",
    "                                             shflx, \\\n",
    "                                             lhflx)))\n",
    "        \n",
    "        nnTarget = np.float32(np.concatenate((tphystnd, phq)))\n",
    "    \n",
    "    elif family == \"relative\":\n",
    "        nnInput = np.float32(np.concatenate((nntbp, \\\n",
    "                                         newhum, \\\n",
    "                                         ps, \\\n",
    "                                         solin, \\\n",
    "                                         shflx, \\\n",
    "                                         lhflx)))\n",
    "                             \n",
    "        nnTarget = np.float32(np.concatenate((tphystnd, phq)))\n",
    "    \n",
    "    if full_run:\n",
    "        nnInput = nnInput[:,:-1,:,:] #the last timestep of a run can have funky values\n",
    "        nnTarget = nnTarget[:,:-1,:,:] #the last timestep of a run can have funky values\n",
    "    \n",
    "    print(\"nnInput\")\n",
    "    nnInput.shape\n",
    "    \n",
    "    print(\"nnTarget\")\n",
    "    nnTarget.shape\n",
    "    \n",
    "    errors = (newhum-oldhum/100).flatten()\n",
    "    result = \"Mean relative humidity conversion error: \" + str(np.mean(errors)) + \"\\n\"\n",
    "    result = result + \"Variance for relative humidity conversion error: \" + str(np.var(errors)) + \"\\n\"\n",
    "    result = result + \"nntbp.shape: \" + str(nntbp.shape) + \"\\n\"\n",
    "    result = result + \"nnqbp.shape: \" + str(nnqbp.shape) + \"\\n\"\n",
    "    result = result + \"lhflx.shape: \" + str(lhflx.shape) + \"\\n\"\n",
    "    result = result + \"shflx.shape: \" + str(shflx.shape) + \"\\n\"\n",
    "    result = result + \"ps.shape: \" + str(ps.shape) + \"\\n\"\n",
    "    result = result + \"solin.shape: \" + str(solin.shape) + \"\\n\"\n",
    "    result = result + \"newhum.shape: \" + str(newhum.shape) + \"\\n\"\n",
    "    result = result + \"oldhum.shape: \" + str(oldhum.shape) + \"\\n\"\n",
    "    result = result + \"tphystnd.shape: \" + str(tphystnd.shape) + \"\\n\"\n",
    "    result = result + \"phq.shape: \" + str(phq.shape) + \"\\n\"\n",
    "    result = result + \"nnInput.shape: \" + str(nnInput.shape) + \"\\n\"\n",
    "    print(result)\n",
    "\n",
    "    if save_diagnostics:\n",
    "        diagnostics = 'diagnostics_' + str(month) + '.txt'\n",
    "        with open(diagnostics, 'a') as fp:\n",
    "            fp.write(result)\n",
    "    \n",
    "    return nnInput, nnTarget\n",
    "\n",
    "def combine_arrays(*args, contiguous = True):\n",
    "    if contiguous: # meaning each spData was part of the same run\n",
    "        return np.concatenate((args), axis = 1)[:,:-1,:,:]\n",
    "    return(np.concatenate((args), axis = 1))\n",
    "                         \n",
    "def sample_indices(size, spacing, fixed = True):\n",
    "    numIndices = np.round(size/spacing)\n",
    "    if fixed:\n",
    "        indices = np.array([int(x) for x in np.round(np.linspace(1,size,int(numIndices)))])-1\n",
    "    else:\n",
    "        indices = list(range(size))\n",
    "        np.random.shuffle(indices)\n",
    "        indices = indices[0:int(numIndices)]\n",
    "    return indices\n",
    "\n",
    "def reshape_input(nnData, subsample = False, spacing = 5):\n",
    "    if subsample:\n",
    "        nnData = nnData[:,:,:,sampleIndices(nnData.shape[3], spacing, True)]\n",
    "    nnData = nnData.ravel(order = 'F').reshape(64,-1,order = 'F')\n",
    "    return nnData\n",
    "\n",
    "def reshape_target(nnData, subsample = False, spacing = 5):\n",
    "    if subsample:\n",
    "        nnData = nnData[:,:,:,sampleIndices(nnData.shape[3], spacing, True)]\n",
    "    nnData = nnData.ravel(order = 'F').reshape(60,-1,order = 'F')\n",
    "    return nnData\n",
    "\n",
    "def normalize_input(family, split = .2):\n",
    "    \n",
    "    # specific heat of air = 1004 J/ K / kg\n",
    "    # latent heat of vaporization 2.5*10^6\n",
    "\n",
    "    heatScale = 1004\n",
    "    moistScale = 2.5e6\n",
    "    \n",
    "    if variation == 0:\n",
    "        with open(path + 'nnDataSpecific_long_5.npy', 'rb') as f:\n",
    "            arr = np.load(f)\n",
    "    if variation == 1:\n",
    "        with open(path + 'nnDataRelative_long_5.npy', 'rb') as f:\n",
    "            arr = np.load(f)\n",
    "    \n",
    "    X = arr[0:64,:].transpose()\n",
    "    y = arr[64:,:].transpose()\n",
    "    \n",
    "    print(\"X_train shape: \")\n",
    "    print(X_train.shape)\n",
    "    print(\"X_test shape: \")\n",
    "    print(X_test.shape)\n",
    "    print(\"y_train shape: \")\n",
    "    print(y_train.shape)\n",
    "    print(\"y_test shape: \")\n",
    "    print(y_test.shape)\n",
    "\n",
    "    train_mu = np.mean(X_train, axis = 0)[:, np.newaxis]\n",
    "    train_std = np.std(X_train, axis = 0)[:, np.newaxis]\n",
    "    train_min = X_train.min(axis = 0)[:, np.newaxis]\n",
    "    train_max = X_train.max(axis = 0)[:, np.newaxis]\n",
    "    \n",
    "    if normalization == \"standard\":\n",
    "        inpsub = train_mu\n",
    "        inpdiv = train_std\n",
    "        \n",
    "    elif normalization == \"range\":\n",
    "        inpsub = train_min\n",
    "        inpdiv = train_max - train_min\n",
    "        \n",
    "    norms_input = [inpsub, inpdiv]\n",
    "    \n",
    "    print(\"INP_SUB shape: \")\n",
    "    print(inpsub.shape)\n",
    "    print(\"INP_DIV shape: \")\n",
    "    print(inpdiv.shape)\n",
    "    \n",
    "    norm_xtrain = (X_train.transpose() - inpsub)/inpdiv\n",
    "    norm_xtrain = norm_xtrain.transpose()\n",
    "    norm_xtest = (X_test.transpose() - inpsub)/inpdiv\n",
    "    norm_xtest = norm_xtest.transpose()\n",
    "\n",
    "    \n",
    "    print(\"norm X_train shape: \")\n",
    "    print(norm_xtrain.shape)\n",
    "    print(\"norm X_test shape: \")\n",
    "    print(norm_xtest.shape)\n",
    "    \n",
    "    return [[norm_xtrain, norm_xtest], norms_input]\n",
    "\n",
    "def normalize_target(variation, path, normalization, split = .2):\n",
    "    \n",
    "    # specific heat of air = 1004 J/ K / kg\n",
    "    # latent heat of vaporization 2.5*10^6\n",
    "\n",
    "    heatScale = 1004\n",
    "    moistScale = 2.5e6\n",
    "    \n",
    "    if variation == 0:\n",
    "        with open(path + 'nnDataSpecific_long_5.npy', 'rb') as f:\n",
    "            arr = np.load(f)\n",
    "    if variation == 1:\n",
    "        with open(path + 'nnDataRelative_long_5.npy', 'rb') as f:\n",
    "            arr = np.load(f)\n",
    "    \n",
    "    print(\"y_train shape: \")\n",
    "    print(y_train.shape)\n",
    "    print(\"y_test shape: \")\n",
    "    print(y_test.shape)\n",
    "\n",
    "    outscale = np.concatenate((np.repeat(heatScale, 30), np.repeat(moistScale, 30)))\n",
    "    \n",
    "    if normalization == \"standard\":\n",
    "        inpsub = train_mu\n",
    "        inpdiv = train_std\n",
    "        \n",
    "    elif normalization == \"range\":\n",
    "        inpsub = train_min\n",
    "        inpdiv = train_max - train_min\n",
    "        \n",
    "    norms_output = outscale\n",
    "    \n",
    "    print(\"INP_SUB shape: \")\n",
    "    print(inpsub.shape)\n",
    "    print(\"INP_DIV shape: \")\n",
    "    print(inpdiv.shape)\n",
    "    print(\"outscale shape: \")\n",
    "    print(outscale.shape)\n",
    "    \n",
    "    norm_ytrain[:, 0:30] = norm_ytrain[:, 0:30]*outscale[0:30]\n",
    "    norm_ytrain[:, 30:60] = norm_ytrain[:, 30:60]*outscale[30:60]\n",
    "    \n",
    "    norm_ytest[:, 0:30] = norm_ytest[:, 0:30]*outscale[0:30]\n",
    "    norm_ytest[:, 30:60] = norm_ytest[:, 30:60]*outscale[30:60]\n",
    "    \n",
    "    print(\"norm y_train shape: \")\n",
    "    print(norm_ytrain.shape)\n",
    "    print(\"norm y_test shape: \")\n",
    "    print(norm_ytest.shape)\n",
    "    \n",
    "    return [[norm_ytrain, norm_ytest], norms_output]\n",
    "\n",
    "def prepare_ingredients32(variation, files, path = \"./\"):\n",
    "    if variation == 0:\n",
    "        path = path + \"specific/\"\n",
    "    if variation == 1:\n",
    "        path = path + \"relative/\"\n",
    "    with open(path + \"trainInput.npy\", 'wb') as f:\n",
    "        np.save(f, np.float32(files[1][0]))\n",
    "    with open(path + \"testInput.npy\", 'wb') as f:\n",
    "        np.save(f, np.float32(files[1][1]))\n",
    "    with open(path + \"trainOutput.npy\", 'wb') as f:\n",
    "        np.save(f, np.float32(files[1][2]))\n",
    "    with open(path + \"testOutput.npy\", 'wb') as f:\n",
    "        np.save(f, np.float32(files[1][3]))\n",
    "    np.savetxt(path + \"normalization/inp_sub.txt\", np.float32(files[2][0]), delimiter=',')\n",
    "    np.savetxt(path + \"normalization/inp_div.txt\", np.float32(files[2][1]), delimiter=',')\n",
    "    np.savetxt(path + \"normalization/out_scale.txt\", np.float32(files[2][2]), delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0dd4d66d-7581-49af-8d41-6b3a9072f379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded in data\n",
      "starting for loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 64/64 [00:03<00:00, 18.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nntbp\n",
      "(30, 95, 64, 128)\n",
      "nnqbp\n",
      "(30, 95, 64, 128)\n",
      "lhflx\n",
      "(1, 95, 64, 128)\n",
      "shflx\n",
      "(1, 95, 64, 128)\n",
      "ps\n",
      "(1, 95, 64, 128)\n",
      "solin\n",
      "(1, 95, 64, 128)\n",
      "newhum\n",
      "(30, 95, 64, 128)\n",
      "oldhum\n",
      "(30, 95, 64, 128)\n",
      "tphystnd\n",
      "(30, 95, 64, 128)\n",
      "phq\n",
      "(30, 95, 64, 128)\n",
      "nnInput\n",
      "nnTarget\n",
      "Mean relative humidity conversion error: 0.0043063145\n",
      "Variance for relative humidity conversion error: 0.00047256332\n",
      "nntbp.shape: (30, 95, 64, 128)\n",
      "nnqbp.shape: (30, 95, 64, 128)\n",
      "lhflx.shape: (1, 95, 64, 128)\n",
      "shflx.shape: (1, 95, 64, 128)\n",
      "ps.shape: (1, 95, 64, 128)\n",
      "solin.shape: (1, 95, 64, 128)\n",
      "newhum.shape: (30, 95, 64, 128)\n",
      "oldhum.shape: (30, 95, 64, 128)\n",
      "tphystnd.shape: (30, 95, 64, 128)\n",
      "phq.shape: (30, 95, 64, 128)\n",
      "nnInput.shape: (64, 95, 64, 128)\n",
      "\n",
      "loaded in data\n",
      "starting for loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 64/64 [00:03<00:00, 17.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nntbp\n",
      "(30, 95, 64, 128)\n",
      "nnqbp\n",
      "(30, 95, 64, 128)\n",
      "lhflx\n",
      "(1, 95, 64, 128)\n",
      "shflx\n",
      "(1, 95, 64, 128)\n",
      "ps\n",
      "(1, 95, 64, 128)\n",
      "solin\n",
      "(1, 95, 64, 128)\n",
      "newhum\n",
      "(30, 95, 64, 128)\n",
      "oldhum\n",
      "(30, 95, 64, 128)\n",
      "tphystnd\n",
      "(30, 95, 64, 128)\n",
      "phq\n",
      "(30, 95, 64, 128)\n",
      "nnInput\n",
      "nnTarget\n",
      "Mean relative humidity conversion error: 0.0041737375\n",
      "Variance for relative humidity conversion error: 0.00046795444\n",
      "nntbp.shape: (30, 95, 64, 128)\n",
      "nnqbp.shape: (30, 95, 64, 128)\n",
      "lhflx.shape: (1, 95, 64, 128)\n",
      "shflx.shape: (1, 95, 64, 128)\n",
      "ps.shape: (1, 95, 64, 128)\n",
      "solin.shape: (1, 95, 64, 128)\n",
      "newhum.shape: (30, 95, 64, 128)\n",
      "oldhum.shape: (30, 95, 64, 128)\n",
      "tphystnd.shape: (30, 95, 64, 128)\n",
      "phq.shape: (30, 95, 64, 128)\n",
      "nnInput.shape: (64, 95, 64, 128)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nnInput_10, nnTarget_10 = make_nninput(do_month(10), \"relative\")\n",
    "nnInput_11, nnTarget_11 = make_nninput(do_month(11), \"relative\")\n",
    "\n",
    "unshaped_input = combine_arrays(nnInput_10, nnInput_11)\n",
    "unshaped_target = combine_arrays(nnTarget_10, nnTarget_11)\n",
    "\n",
    "reshaped_input = reshape_input(combine_arrays(nnInput_10, nnInput_11))\n",
    "reshaped_target = reshape_target(combine_arrays(nnTarget_10, nnTarget_11))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "612368bb-c7a9-48bb-84d3-f3f30f0b2b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 189, 64, 128)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unshaped_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8367b418-b719-4bd4-82d5-cf2a0eb02fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 189, 64, 128)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unshaped_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "75610b98-0943-4f10-b727-2d306ad1663e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 1548288)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0601c588-9c41-4177-9b22-53cd2c5bfd3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 1548288)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c4e29a8b-4b8f-4822-a8dc-e548c8b81ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1548288"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "189*64*128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69c6b176-3d1a-4b4d-adb3-4b17ffeb8d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 190, 64, 128)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e09b9ffd-da19-4c3d-b73b-dd76fc8d4b06",
   "metadata": {},
   "source": [
    "# run the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67592cb2-9c14-4d60-9975-937ae1e1f82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saveNNInput(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c703eb64-1026-4d95-b5ee-ad9adf4758a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saveNNInput(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808276fe-3894-40f0-bc3a-e5d4dd95d30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saveNNInput(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e62ce0-0a4b-4df4-ad7d-6bc5eb905d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saveNNInput(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023a6d72-01bd-4434-b640-5269e9a8c4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saveNNInput(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
