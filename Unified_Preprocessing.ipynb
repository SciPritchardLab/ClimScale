{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d960a771-e28a-41a4-973a-6f918515caee",
   "metadata": {},
   "source": [
    "# Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78f301d3-300d-4051-a1e5-cd598f0b2840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d32a25-2057-410a-b8d8-86a4e1039307",
   "metadata": {},
   "source": [
    "# Relative Humidity Conversion Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c44f6859-feb5-47b5-90af-998a5ea8e0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliq(T):\n",
    "    a_liq = np.float32(np.array([-0.976195544e-15,-0.952447341e-13,\\\n",
    "                                 0.640689451e-10,\\\n",
    "                      0.206739458e-7,0.302950461e-5,0.264847430e-3,\\\n",
    "                      0.142986287e-1,0.443987641,6.11239921]));\n",
    "    c_liq = np.float32(-80.0)\n",
    "    T0 = np.float32(273.16)\n",
    "    return np.float32(100.0)*np.polyval(a_liq,np.maximum(c_liq,T-T0))\n",
    "\n",
    "def eice(T):\n",
    "    a_ice = np.float32(np.array([0.252751365e-14,0.146898966e-11,0.385852041e-9,\\\n",
    "                      0.602588177e-7,0.615021634e-5,0.420895665e-3,\\\n",
    "                      0.188439774e-1,0.503160820,6.11147274]));\n",
    "    c_ice = np.float32(np.array([273.15,185,-100,0.00763685,0.000151069,7.48215e-07]))\n",
    "    T0 = np.float32(273.16)\n",
    "    return np.where(T>c_ice[0],eliq(T),\\\n",
    "                   np.where(T<=c_ice[1],np.float32(100.0)*(c_ice[3]+np.maximum(c_ice[2],T-T0)*\\\n",
    "                   (c_ice[4]+np.maximum(c_ice[2],T-T0)*c_ice[5])),\\\n",
    "                           np.float32(100.0)*np.polyval(a_ice,T-T0)))\n",
    "\n",
    "def esat(T):\n",
    "    T0 = np.float32(273.16)\n",
    "    T00 = np.float32(253.16)\n",
    "    omtmp = (T-T00)/(T0-T00)\n",
    "    omega = np.maximum(np.float32(0.0),np.minimum(np.float32(1.0),omtmp))\n",
    "    return np.where(T>T0,eliq(T),np.where(T<T00,eice(T),(omega*eliq(T)+(1-omega)*eice(T))))\n",
    "\n",
    "def RH(T,qv,P0,PS,hyam,hybm):\n",
    "    R = np.float32(287.0)\n",
    "    Rv = np.float32(461.0)\n",
    "    p = P0 * hyam + PS[:, None] * hybm # Total pressure (Pa)\n",
    "    \n",
    "    T = np.float32(T)\n",
    "    qv = np.float32(qv)\n",
    "    p = np.float32(p)\n",
    "    \n",
    "    return Rv*p*qv/(R*esat(T))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90850a52-7916-47d1-8af1-f28738c16f79",
   "metadata": {},
   "source": [
    "# Data Processing Functions (Part 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7ec4896-7cff-4b0e-885a-8a4f48834642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doMonth(month):\n",
    "    datasets = !ls\n",
    "    n = str(month)\n",
    "    datasets = [x for x in datasets if \"h1.0000-\" + n.zfill(2) in x]\n",
    "    return xr.open_mfdataset(datasets)\n",
    "\n",
    "def makeSuffix(month):\n",
    "    n = str(month)\n",
    "    return \"_\" + n.zfill(2)\n",
    "\n",
    "def saveNNInput(month):\n",
    "    spData = doMonth(month)\n",
    "    suffix = makeSuffix(month)\n",
    "    print(\"read in data\")\n",
    "    nntbp = spData[\"NNTBP\"].values\n",
    "    nnqbp = spData[\"NNQBP\"].values\n",
    "    p0 = spData[\"P0\"].values\n",
    "    ps = spData[\"NNPS\"].values\n",
    "    hyam = spData[\"hyam\"].values\n",
    "    hybm = spData[\"hybm\"].values\n",
    "    relhum = spData[\"RELHUM\"].values\n",
    "    tphystnd = spData[\"TPHYSTND\"].values\n",
    "    phq = spData[\"PHQ\"].values\n",
    "\n",
    "    p0 = np.array(list(set(p0)))\n",
    "    print(\"loaded in data\")\n",
    "    newhum = np.zeros((spData[\"time\"].shape[0],\\\n",
    "                         spData[\"lev\"].shape[0], \\\n",
    "                         spData[\"lat\"].shape[0], \\\n",
    "                         spData[\"lon\"].shape[0]))\n",
    "    lats = spData[\"lat\"]\n",
    "    lons = spData[\"lon\"]\n",
    "    print(\"starting for loop\")\n",
    "    for i in tqdm(range(len(lats))):\n",
    "        for j in range(len(lons)):\n",
    "            latIndex = i\n",
    "            lonIndex = j\n",
    "            R = np.float32(287.0)\n",
    "            Rv = np.float32(461.0)\n",
    "            p = p0 * hyam + ps[:, None, latIndex, lonIndex] * hybm # Total pressure (Pa)\n",
    "\n",
    "            T = np.float32(nntbp[:, :, latIndex, lonIndex])\n",
    "            qv = np.float32(nnqbp[:, :, latIndex, lonIndex])\n",
    "            p = np.float32(p)\n",
    "            newhum[:,:, latIndex, lonIndex] = Rv*p*qv/(R*esat(T))\n",
    "    \n",
    "    nntbp = np.moveaxis(nntbp[1:,:,:,:],0,1)\n",
    "    print(\"nntbp\")\n",
    "    print(nntbp.shape)\n",
    "    \n",
    "    nnqbp = np.moveaxis(nnqbp[1:,:,:,:],0,1)\n",
    "    print(\"nnqbp\")\n",
    "    print(nnqbp.shape)\n",
    "    \n",
    "    lhflx = spData[\"LHFLX\"].values[np.newaxis,:-1,:,:]\n",
    "    print(\"lhflx\")\n",
    "    print(lhflx.shape)\n",
    "    \n",
    "    shflx = spData[\"SHFLX\"].values[np.newaxis,:-1,:,:]\n",
    "    print(\"shflx\")\n",
    "    print(shflx.shape)\n",
    "    \n",
    "    ps = spData[\"NNPS\"].values[np.newaxis,1:,:,:]\n",
    "    print(\"ps\")\n",
    "    print(ps.shape)\n",
    "    \n",
    "    solin = spData[\"SOLIN\"].values[np.newaxis,1:,:,:]\n",
    "    print(\"solin\")\n",
    "    print(solin.shape)\n",
    "    \n",
    "    newhum = np.moveaxis(newhum[1:,:,:,:],0,1)\n",
    "    print(\"newhum\")\n",
    "    print(newhum.shape)\n",
    "    \n",
    "    oldhum = np.moveaxis(relhum[1:,:,:,:],0,1)\n",
    "    print(\"oldhum\")\n",
    "    print(oldhum.shape)\n",
    "    \n",
    "    tphystnd = np.moveaxis(tphystnd[1:,:,:,:],0,1)\n",
    "    print(\"tphystnd\")\n",
    "    print(tphystnd.shape)\n",
    "    \n",
    "\n",
    "    phq = np.moveaxis(phq[1:,:,:,:],0,1)\n",
    "    print(\"phq\")\n",
    "    print(phq.shape)\n",
    "\n",
    "    nnInput = np.concatenate((nntbp, \\\n",
    "                              nnqbp, \\\n",
    "                              lhflx, \\\n",
    "                              shflx, \\\n",
    "                              ps, \\\n",
    "                              solin, \\\n",
    "                              newhum, \\\n",
    "                              oldhum, \\\n",
    "                              tphystnd, \\\n",
    "                              phq))\n",
    "    print(\"nnInput\")\n",
    "    nnInput.shape\n",
    "\n",
    "    errors = (newhum-oldhum/100).flatten()\n",
    "    result = \"Mean error: \" + str(np.mean(errors)) + \"\\n\"\n",
    "    result = result + \"Variance: \" + str(np.var(errors)) + \"\\n\"\n",
    "    result = result + \"nntbp.shape: \" + str(nntbp.shape) + \"\\n\"\n",
    "    result = result + \"nnqbp.shape: \" + str(nnqbp.shape) + \"\\n\"\n",
    "    result = result + \"lhflx.shape: \" + str(lhflx.shape) + \"\\n\"\n",
    "    result = result + \"shflx.shape: \" + str(shflx.shape) + \"\\n\"\n",
    "    result = result + \"ps.shape: \" + str(ps.shape) + \"\\n\"\n",
    "    result = result + \"solin.shape: \" + str(solin.shape) + \"\\n\"\n",
    "    result = result + \"newhum.shape: \" + str(newhum.shape) + \"\\n\"\n",
    "    result = result + \"oldhum.shape: \" + str(oldhum.shape) + \"\\n\"\n",
    "    result = result + \"tphystnd.shape: \" + str(tphystnd.shape) + \"\\n\"\n",
    "    result = result + \"phq.shape: \" + str(phq.shape) + \"\\n\"\n",
    "    result = result + \"nnInput.shape: \" + str(nnInput.shape) + \"\\n\"\n",
    "    print(result)\n",
    "    \n",
    "    #added 32 bit fix\n",
    "    nnInput = np.float32(nnInput)\n",
    "    \n",
    "    fileName = 'nnInput' + suffix + '.npy'\n",
    "    with open(fileName, 'wb') as f:\n",
    "        np.save(f, nnInput)\n",
    "\n",
    "    diagnostics = 'diagnostics' + suffix + '.txt'\n",
    "    with open(diagnostics, 'a') as fp:\n",
    "        fp.write(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb3e733-3902-45f8-ae3a-ae273d24eb39",
   "metadata": {},
   "source": [
    "# Data Processing Functions (Part 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0f6a06-0b07-4c57-9135-08b9c807144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/ocean/projects/atm200007p/jlin96/longSPrun/\"\n",
    "subFolders = !ls\n",
    "files = [path + x for x in subFolders if \"nnInput\" in x]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8499143-d3e6-4a5b-a189-4f069cbcdd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleIndices(size, spacing, fixed = True):\n",
    "    numIndices = np.round(size/spacing)\n",
    "    if fixed:\n",
    "        indices = np.array([int(x) for x in np.round(np.linspace(1,size,int(numIndices)))])-1\n",
    "    else:\n",
    "        indices = list(range(size))\n",
    "        np.random.shuffle(indices)\n",
    "        indices = indices[0:int(numIndices)]\n",
    "    return indices\n",
    "\n",
    "def shrinkArray(nnData, spacing):\n",
    "    nnData = nnData[:,:,:,sampleIndices(nnData.shape[3], spacing, True)]\n",
    "    nnData = nnData.ravel(order = 'F').reshape(184,-1,order = 'F')\n",
    "    return nnData\n",
    "\n",
    "def splitArray(nnData, variant):\n",
    "    if variant == 0:\n",
    "        nnInput = nnData[0:64,:]\n",
    "    if variant == 1:\n",
    "        nnInput = np.concatenate((nnData[:30,:],nnData[64:94,:], nnData[60:64,:]))\n",
    "    #nnTarget = nnData[124:,:]\n",
    "    nnVariant = np.concatenate((nnInput, nnData[124:,:]))\n",
    "    return nnVariant\n",
    "\n",
    "def reorderArray(nnData):\n",
    "    canonical = np.concatenate([nnData[0:30,:], \\\n",
    "                                nnData[30:60,:], \\\n",
    "                                nnData[62:63,:], \\\n",
    "                                nnData[63:64,:], \\\n",
    "                                nnData[61:62,:], \\\n",
    "                                nnData[60:61,:], \\\n",
    "                                nnData[64:94,:], \\\n",
    "                                nnData[94:124,:]], axis = 0)\n",
    "    return canonical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f10729-a6a8-4943-b326-ebe7ebb3787a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "for arr in tqdm(files):\n",
    "    with open(arr, 'rb') as f:\n",
    "        nnData = np.load(f)\n",
    "        nnData = nnData[:,:-1,:,:] # this was to account for the weird humidity error at the end.\n",
    "    datasets.append(shrinkArray(nnData, 5))\n",
    "    del nnData\n",
    "combinedData = np.concatenate(datasets, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d423c2b1-c58a-4b2d-ad0a-b1fe140ddbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_specific = splitArray(combinedData, 0)\n",
    "del combinedData\n",
    "\n",
    "path = \"/ocean/projects/atm200007p/jlin96/nnIngredientFactory/preprocessing/ingredientsLong/\"\n",
    "\n",
    "with open(path + 'nnDataSpecific_long_5.npy', 'wb') as f:\n",
    "    np.save(f, rearrangedSpecific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbfd226-920e-41ba-9d07-11b2520efcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_relative = splitArray(combinedData, 1)\n",
    "del combinedData\n",
    "\n",
    "path = \"/ocean/projects/atm200007p/jlin96/nnIngredientFactory/preprocessing/ingredientsLong/\"\n",
    "\n",
    "with open(path + 'nnDataRelative_long_5.npy', 'wb') as f:\n",
    "    np.save(f, rearrangedRelative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc68ead-e0c8-4261-b9c8-152a9b843650",
   "metadata": {},
   "source": [
    "# Data Processing Functions (Part 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca3cfde-8675-46a0-8526-e4e55e1e30aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
