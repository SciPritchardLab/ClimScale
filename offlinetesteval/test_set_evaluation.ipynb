{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d01f5cb-8d9f-435d-b723-5cd96ba4049c",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b803089e-8c48-4e79-a7be-7915c7d230aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import scipy.integrate as integrate\n",
    "from tensorflow import keras\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e5c473-449d-4c6e-95b4-bd142bc8f568",
   "metadata": {},
   "source": [
    "# Load data, normalization, and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e16be0b-1b67-4d2d-b9b9-feabc61702b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_name = \"expanded\"\n",
    "timesteps = 48*2\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f131d1e-5009-4d69-aef8-20df06b33ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checktime():\n",
    "    print(datetime.datetime.now()) \n",
    "#change base path later for functional programming approach\n",
    "\n",
    "data_path = \"testing_data/\"\n",
    "norm_path = \"norm_files/\"\n",
    "model_path = \"../coupling_folder/h5_models/\"\n",
    "\n",
    "num_models = 330\n",
    "\n",
    "inpsub = np.loadtxt(norm_path + \"inp_sub.txt\")\n",
    "inpdiv = np.loadtxt(norm_path + \"inp_div.txt\")\n",
    "\n",
    "heatScale = 1004\n",
    "moistScale = 2.5e6\n",
    "outscale = np.concatenate((np.repeat(heatScale, 30), np.repeat(moistScale, 30)))\n",
    "\n",
    "with open(data_path + 'test_input.npy', 'rb') as f:\n",
    "    test_input = np.load(f)[:,0:timesteps,:,:]\n",
    "    \n",
    "with open(data_path + 'test_target.npy', 'rb') as f:\n",
    "    test_target = np.load(f)[:,0:timesteps,:,:]\n",
    "    \n",
    "nn_input = (test_input-inpsub[:,np.newaxis,np.newaxis,np.newaxis])/inpdiv[:,np.newaxis,np.newaxis,np.newaxis]\n",
    "\n",
    "spData = xr.open_mfdataset([\"/ocean/projects/atm200007p/jlin96/longSPrun_o3/AndKua_aqua_Base_training.cam2.h1.0001-01-19-00000.nc\", \\\n",
    "                            \"/ocean/projects/atm200007p/jlin96/longSPrun_o3/AndKua_aqua_Base_training.cam2.h1.0001-01-20-00000.nc\"], \\\n",
    "                            decode_times = False)\n",
    "\n",
    "assert test_input.shape[1] == test_target.shape[1]\n",
    "\n",
    "#Creating mass weights\n",
    "def createPressureGrid(h1Data):\n",
    "    hyam = np.array(h1Data[\"hyam\"])\n",
    "    hybm = np.array(h1Data[\"hybm\"])\n",
    "    ps = np.array(h1Data[\"NNPS\"])\n",
    "    lats = np.array(h1Data[\"lat\"])\n",
    "    lons = np.array(h1Data[\"lon\"])\n",
    "    levs = 30\n",
    "    times = np.array(range(len(ps)))\n",
    "    pressureGrid = np.zeros([len(times), 30, len(lats), len(lons)])\n",
    "    for t in range(len(times)):\n",
    "        for lat in range(len(lats)):\n",
    "            for lon in range(len(lons)):\n",
    "                pressureGrid[t, :, lat, lon]  = hyam[t]*1e5 + ps[t][lat][lon]*hybm[t]\n",
    "    return np.diff(pressureGrid, axis = 1)\n",
    "pressures = np.mean(createPressureGrid(spData), axis = 0)[11:29]\n",
    "mass_weights = pressures/sum(pressures.flatten())\n",
    "\n",
    "#Creating area weights\n",
    "r = 6371\n",
    "def integrand(t):\n",
    "    return math.sin(t)\n",
    "\n",
    "def surfArea(lat1, lat2, lon1, lon2):\n",
    "    lat1 = lat1 + 90\n",
    "    lat2 = lat2 + 90\n",
    "    lat1 = min(lat1,lat2)*math.pi/180\n",
    "    lat2 = max(lat1, lat2)*math.pi/180\n",
    "    lons = (max(lon1, lon2) - min(lon1, lon2))*math.pi/180\n",
    "    a = integrate.quad(integrand, lat1, lat2)\n",
    "    #max error is 2nd arg for a\n",
    "    return lons*r*r*a[0]\n",
    "\n",
    "# Longitudes are equidistant so we can simplify surfArea\n",
    "def weight_area(lat1, lat2):\n",
    "    lat1 = lat1 + 90\n",
    "    lat2 = lat2 + 90\n",
    "    lat1 = min(lat1,lat2)*math.pi/180\n",
    "    lat2 = max(lat1, lat2)*math.pi/180\n",
    "    weight = integrate.quad(integrand, lat1, lat2)\n",
    "    return weight[0]\n",
    "\n",
    "lats = np.array(spData[\"lat\"])\n",
    "assert(90+lats[0]==90-lats[63])\n",
    "last_lat_mdiff = 90+lats[0]\n",
    "lat_mdiff = np.diff(lats)/2\n",
    "lat_buff = np.append(lat_mdiff, last_lat_mdiff)\n",
    "lat_edges = lat_buff + lats\n",
    "lat_edges = np.append(-90, lat_edges)\n",
    "area_weights = []\n",
    "for i in range(len(lats)):\n",
    "    area_weights.append(weight_area(lat_edges[i],lat_edges[i+1]))\n",
    "area_weights = np.array(area_weights)\n",
    "area_weights = area_weights[np.newaxis,:,np.newaxis]\n",
    "\n",
    "error_weights = area_weights * pressures\n",
    "error_weights = error_weights/sum(error_weights.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e983bf71-132a-4a2e-88c5-5932117089b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a36e967-37d8-4d57-9e1f-e2ffa150b95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c211448b-d7c7-4bea-83c9-c03ab2b28c4b",
   "metadata": {},
   "source": [
    "# Functions for getting predictions and mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624965d4-9122-46ae-9b9b-d728a34fedcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(proj_name, model_rank):\n",
    "    f_load = model_path + '%s_model_%03d.h5'%(proj_name, model_rank)\n",
    "    model = keras.models.load_model(f_load, compile=False)\n",
    "    unrolled = np.reshape(nn_input, (125, -1)).transpose()\n",
    "    prediction = model.predict(unrolled).transpose()/outscale[:,np.newaxis]\n",
    "    prediction = np.reshape(prediction, (60, timesteps, 64, 128))\n",
    "    return prediction\n",
    "\n",
    "def squared_error(prediction, target):\n",
    "    se = (prediction-target)**2\n",
    "    se_T = np.mean(se[0:30,:,:,:], axis = 1)\n",
    "    se_Q = np.mean(se[30:60,:,:,:], axis = 1)\n",
    "    return se_T, se_Q\n",
    "\n",
    "def weight_error(se):\n",
    "    return se[12:30]*error_weights\n",
    "\n",
    "def root_error(wse):\n",
    "    return np.sum(wse)**.5\n",
    "\n",
    "def get_rmse(prediction, target):\n",
    "    se_T, se_Q = squared_error(prediction, target)\n",
    "    rmse_T = root_error(weight_error(se_T))\n",
    "    rmse_Q = root_error(weight_error(se_Q))\n",
    "    return rmse_T, rmse_Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db8220c-485e-4a15-b235-084753bb5e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = []\n",
    "for i in tqdm(range(num_models)):\n",
    "    model_rank = i+1\n",
    "    rmse_T, rmse_Q = get_rmse(get_prediction(proj_name, model_rank), test_target)\n",
    "    rmse.append([rmse_T, rmse_Q])\n",
    "rmse = np.array(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca71d67-65f3-48d2-a484-703f0d8280b5",
   "metadata": {},
   "source": [
    "# Save offline errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748a7810-0f15-458a-b010-afc0963b640b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"offline_errors/\"\n",
    "with open(save_path + \"rmse.npy\", 'wb') as f:\n",
    "    np.save(f, np.float32(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf2737f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a65d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
