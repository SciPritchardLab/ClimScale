{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import scipy.integrate as integrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('training/training_data/train_input.npy', 'rb') as f:\n",
    "    train_input = np.load(f)\n",
    "\n",
    "with open('training/training_data/train_target.npy', 'rb') as f:\n",
    "    train_target = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17927168, 64)\n",
      "(17927168, 60)\n"
     ]
    }
   ],
   "source": [
    "print(train_input.shape)\n",
    "print(train_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17927168, 65)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias = np.ones((train_input.shape[0], 1))\n",
    "train_input = np.concatenate((train_input, bias), axis=1)\n",
    "train_input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train MLR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_transpose = np.transpose(train_input)\n",
    "X_transpose_X = train_input_transpose@train_input\n",
    "X_transpose_X_inverse = np.linalg.inv(X_transpose_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 65)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transpose_X_inverse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 65)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transpose_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 17927168)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_transpose.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17927168, 60)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transpose_y = train_input_transpose@train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 60)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transpose_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr_weights = X_transpose_X_inverse@X_transpose_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 60)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlr_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr_pred = train_input@mlr_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17927168, 60)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlr_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training mse\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0020987695984448136"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"training mse\")\n",
    "np.mean((train_target-mlr_pred)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsampling = 3\n",
    "def sample_indices(size, spacing, fixed = True):\n",
    "    numIndices = np.round(size/spacing)\n",
    "    if fixed:\n",
    "        indices = np.array([int(x) for x in np.round(np.linspace(1,size,int(numIndices)))])-1\n",
    "    else:\n",
    "        indices = list(range(size))\n",
    "        np.random.shuffle(indices)\n",
    "        indices = indices[0:int(numIndices)]\n",
    "    return indices\n",
    "\n",
    "data_path = \"offlinetesteval/testing_data/\"\n",
    "norm_path = \"offlinetesteval/norm_files/\"\n",
    "\n",
    "num_models = 330\n",
    "\n",
    "inpsub = np.loadtxt(norm_path + \"inp_sub.txt\")\n",
    "inpdiv = np.loadtxt(norm_path + \"inp_div.txt\")\n",
    "\n",
    "heatScale = 1004\n",
    "moistScale = 2.5e6\n",
    "outscale = np.concatenate((np.repeat(heatScale, 30), np.repeat(moistScale, 30)))\n",
    "\n",
    "with open(data_path + 'test_input.npy', 'rb') as f:\n",
    "    test_input = np.load(f)[:,sample_indices(336, subsampling),:,:]\n",
    "    \n",
    "with open(data_path + 'test_target.npy', 'rb') as f:\n",
    "    test_target = np.load(f)[:,sample_indices(336, subsampling),:,:]\n",
    "    \n",
    "assert test_input.shape[1]==test_target.shape[1]\n",
    "\n",
    "timesteps = test_input.shape[1]\n",
    "    \n",
    "nn_input = (test_input-inpsub[:,np.newaxis,np.newaxis,np.newaxis])/inpdiv[:,np.newaxis,np.newaxis,np.newaxis]\n",
    "\n",
    "spData = xr.open_mfdataset([\"/ocean/projects/atm200007p/jlin96/longSPrun_o3/AndKua_aqua_Base_training.cam2.h1.0001-01-19-00000.nc\", \\\n",
    "                            \"/ocean/projects/atm200007p/jlin96/longSPrun_o3/AndKua_aqua_Base_training.cam2.h1.0001-01-20-00000.nc\"], \\\n",
    "                            decode_times = False)\n",
    "\n",
    "assert test_input.shape[1] == test_target.shape[1]\n",
    "\n",
    "#Creating mass weights\n",
    "def createPressureGrid(h1Data):\n",
    "    hyam = np.array(h1Data[\"hyam\"])\n",
    "    hybm = np.array(h1Data[\"hybm\"])\n",
    "    ps = np.array(h1Data[\"NNPS\"])\n",
    "    lats = np.array(h1Data[\"lat\"])\n",
    "    lons = np.array(h1Data[\"lon\"])\n",
    "    levs = 30\n",
    "    times = np.array(range(len(ps)))\n",
    "    pressureGrid = np.zeros([len(times), 30, len(lats), len(lons)])\n",
    "    for t in range(len(times)):\n",
    "        for lat in range(len(lats)):\n",
    "            for lon in range(len(lons)):\n",
    "                pressureGrid[t, :, lat, lon]  = hyam[t]*1e5 + ps[t][lat][lon]*hybm[t]\n",
    "    return np.diff(pressureGrid, axis = 1)\n",
    "pressures = np.mean(createPressureGrid(spData), axis = 0)#[11:29]\n",
    "mass_weights = pressures/sum(pressures.flatten())\n",
    "\n",
    "#Creating area weights\n",
    "r = 6371\n",
    "def integrand(t):\n",
    "    return math.sin(t)\n",
    "\n",
    "def surfArea(lat1, lat2, lon1, lon2):\n",
    "    lat1 = lat1 + 90\n",
    "    lat2 = lat2 + 90\n",
    "    lat1 = min(lat1,lat2)*math.pi/180\n",
    "    lat2 = max(lat1, lat2)*math.pi/180\n",
    "    lons = (max(lon1, lon2) - min(lon1, lon2))*math.pi/180\n",
    "    a = integrate.quad(integrand, lat1, lat2)\n",
    "    #max error is 2nd arg for a\n",
    "    return lons*r*r*a[0]\n",
    "\n",
    "# Longitudes are equidistant so we can simplify surfArea\n",
    "def weight_area(lat1, lat2):\n",
    "    lat1 = lat1 + 90\n",
    "    lat2 = lat2 + 90\n",
    "    lat1 = min(lat1,lat2)*math.pi/180\n",
    "    lat2 = max(lat1, lat2)*math.pi/180\n",
    "    weight = integrate.quad(integrand, lat1, lat2)\n",
    "    return weight[0]\n",
    "\n",
    "lats = np.array(spData[\"lat\"])\n",
    "assert(90+lats[0]==90-lats[63])\n",
    "last_lat_mdiff = 90+lats[0]\n",
    "lat_mdiff = np.diff(lats)/2\n",
    "lat_buff = np.append(lat_mdiff, last_lat_mdiff)\n",
    "lat_edges = lat_buff + lats\n",
    "lat_edges = np.append(-90, lat_edges)\n",
    "area_weights = []\n",
    "for i in range(len(lats)):\n",
    "    area_weights.append(weight_area(lat_edges[i],lat_edges[i+1]))\n",
    "area_weights = np.array(area_weights)\n",
    "area_weights = area_weights[np.newaxis,:,np.newaxis]\n",
    "\n",
    "error_weights = area_weights * pressures\n",
    "error_weights = error_weights/sum(error_weights.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 112, 64, 128)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 112, 64, 128)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(917504, 65)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlr_input = np.reshape(nn_input, (64, -1)).transpose()\n",
    "bias = np.ones((mlr_input.shape[0], 1))\n",
    "mlr_input = np.concatenate((mlr_input, bias), axis=1)\n",
    "mlr_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr_pred_test = mlr_input@mlr_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(917504, 60)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlr_pred_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outscale = np.concatenate((np.repeat(heatScale, 30), np.repeat(moistScale, 30)))[:, np.newaxis]\n",
    "outscale.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 917504)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlr_pred_test = mlr_pred_test.transpose()/outscale\n",
    "mlr_pred_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 112, 64, 128)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlr_pred_test = np.reshape(mlr_pred_test, (60, 112, 64, 128))\n",
    "mlr_pred_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_error(prediction, target):\n",
    "    se = (prediction-target)**2\n",
    "    se_T = np.mean(se[0:30,:,:,:], axis = 1)\n",
    "    se_Q = np.mean(se[30:60,:,:,:], axis = 1)\n",
    "    return se_T, se_Q\n",
    "\n",
    "def weight_error(se):\n",
    "    # return se[12:30]*error_weights\n",
    "    return se*error_weights\n",
    "\n",
    "def root_error(wse):\n",
    "    return np.sum(wse)**.5\n",
    "\n",
    "def get_rmse(prediction, target):\n",
    "    se_T, se_Q = squared_error(prediction, target)\n",
    "    rmse_T = root_error(weight_error(se_T))\n",
    "    rmse_Q = root_error(weight_error(se_Q))\n",
    "    return rmse_T, rmse_Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.663343097627819e-05, 3.1025109112159054e-08)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rmse(mlr_pred_test, test_target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
