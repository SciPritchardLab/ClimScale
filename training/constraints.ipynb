{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar 11 16:40:56 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-SXM2-32GB           On  | 00000000:16:00.0 Off |                    0 |\n",
      "| N/A   37C    P0              40W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2-32GB           On  | 00000000:3A:00.0 Off |                    0 |\n",
      "| N/A   26C    P0              39W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2-32GB           On  | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   30C    P0              39W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2-32GB           On  | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   24C    P0              38W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp training_data/* /dev/shm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "memory_map = True\n",
    "if memory_map:\n",
    "    train_input = np.load('/dev/shm/train_input.npy', mmap_mode='r')\n",
    "    train_target = np.load('/dev/shm/train_target.npy', mmap_mode='r')\n",
    "    val_input = np.load('/dev/shm/val_input.npy', mmap_mode='r')\n",
    "    val_target = np.load('/dev/shm/val_target.npy', mmap_mode='r')\n",
    "else:\n",
    "    train_input = np.load('/dev/shm/train_input.npy')\n",
    "    train_target = np.load('/dev/shm/train_target.npy')\n",
    "    val_input = np.load('/dev/shm/val_input.npy')\n",
    "    val_target = np.load('/dev/shm/val_target.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 16:49:11.250632: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-11 16:49:20.882129: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-11 16:49:24.405901: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-11 16:49:55.331199: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/packages/cuda/v11.7.1/lib64:/opt/packages/cuda/v11.7.1/nvvm/lib64:/opt/packages/cuda/v11.7.1/extras/CUPTI/lib64:/jet/home/jlin96/.conda/envs/tf2/lib/\n",
      "2024-03-11 16:49:55.332608: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/packages/cuda/v11.7.1/lib64:/opt/packages/cuda/v11.7.1/nvvm/lib64:/opt/packages/cuda/v11.7.1/extras/CUPTI/lib64:/jet/home/jlin96/.conda/envs/tf2/lib/\n",
      "2024-03-11 16:49:55.332635: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dropout\n",
    "import tensorflow_addons as tfa\n",
    "from qhoptim.tf import QHAdamOptimizer\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "import keras_tuner as kt\n",
    "import os\n",
    "import logging\n",
    "\n",
    "def build_model(hp):\n",
    "    alpha = hp.Float(\"leak\", min_value = 0, max_value = .4)\n",
    "    dp_rate = hp.Float(\"dropout\", min_value = 0, max_value = .25)\n",
    "    batch_norm = hp.Boolean(\"batch_normalization\")\n",
    "    model = Sequential()\n",
    "    hiddenUnits = hp.Int(\"hidden_units\", min_value = 200, max_value = 480)\n",
    "    model.add(Dense(units = hiddenUnits, input_dim=175, kernel_initializer='normal'))\n",
    "    model.add(LeakyReLU(alpha = alpha))\n",
    "    if batch_norm:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Dropout(dp_rate))\n",
    "    for i in range(hp.Int(\"num_layers\", min_value = 4, max_value = 11)):\n",
    "        model.add(Dense(units = hiddenUnits, kernel_initializer='normal'))\n",
    "        model.add(LeakyReLU(alpha = alpha))\n",
    "        if batch_norm:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(Dropout(dp_rate))\n",
    "    model.add(Dense(55, kernel_initializer='normal', activation='linear'))\n",
    "    initial_learning_rate = hp.Float(\"lr\", min_value=1e-6, max_value=1e-3, sampling=\"log\")\n",
    "    optimizer = hp.Choice(\"optimizer\", [\"adam\", \"RAdam\", \"QHAdam\"])\n",
    "    if optimizer == \"adam\":\n",
    "        optimizer = keras.optimizers.Adam(learning_rate = initial_learning_rate)\n",
    "    elif optimizer == \"RAdam\":\n",
    "        optimizer = tfa.optimizers.RectifiedAdam(learning_rate = initial_learning_rate)\n",
    "    elif optimizer == \"QHAdam\":\n",
    "        optimizer = QHAdamOptimizer(learning_rate = initial_learning_rate, nu2=1.0, beta1=0.995, beta2=0.999)\n",
    "    model.compile(optimizer = optimizer, loss = 'mse', metrics = [\"mse\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 16:50:54.039281: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-11 16:51:01.716705: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31095 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:16:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "0.34467           |?                 |leak\n",
      "0.060967          |?                 |dropout\n",
      "True              |?                 |batch_normalization\n",
      "471               |?                 |hidden_units\n",
      "9                 |?                 |num_layers\n",
      "0.00026052        |?                 |lr\n",
      "RAdam             |?                 |optimizer\n",
      "\n",
      "Epoch 1/8\n",
      "14341/14341 - 597s - loss: 0.4938 - mse: 0.4938 - val_loss: 0.7181 - val_mse: 0.7181 - lr: 2.6052e-04 - 597s/epoch - 42ms/step\n",
      "Epoch 2/8\n",
      "14341/14341 - 576s - loss: 0.4394 - mse: 0.4394 - val_loss: 0.5549 - val_mse: 0.5549 - lr: 2.6052e-04 - 576s/epoch - 40ms/step\n",
      "Epoch 3/8\n",
      "14341/14341 - 590s - loss: 0.4128 - mse: 0.4128 - val_loss: 0.5221 - val_mse: 0.5221 - lr: 2.6052e-04 - 590s/epoch - 41ms/step\n",
      "Epoch 4/8\n",
      "14341/14341 - 586s - loss: 0.4050 - mse: 0.4050 - val_loss: 0.5257 - val_mse: 0.5257 - lr: 2.6052e-04 - 586s/epoch - 41ms/step\n",
      "Epoch 5/8\n",
      "14341/14341 - 588s - loss: 0.3996 - mse: 0.3996 - val_loss: 0.5211 - val_mse: 0.5211 - lr: 2.6052e-04 - 588s/epoch - 41ms/step\n",
      "Epoch 6/8\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5000\n",
    "num_epochs = 8\n",
    "shuffle_buffer = 50000\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((train_input, train_target))\n",
    "    val_ds = tf.data.Dataset.from_tensor_slices((val_input, val_target))\n",
    "\n",
    "    # Applying transformations to the dataset:\n",
    "    # Shuffle, batch, and prefetch for the training dataset\n",
    "    train_ds = train_ds.shuffle(buffer_size=shuffle_buffer) # Shuffle the data\n",
    "    train_ds = train_ds.batch(batch_size, drop_remainder=True)  # Batch the data\n",
    "    train_ds = train_ds.prefetch(tf.data.AUTOTUNE)  # Prefetch for efficiency\n",
    "\n",
    "    # Batch and prefetch for the validation dataset\n",
    "    val_ds = val_ds.batch(batch_size)\n",
    "    val_ds = val_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "def lr_schedule(epoch, lr):\n",
    "    if epoch < 5:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"val_mse\",\n",
    "    max_trials=1,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=False,\n",
    "    directory=\"tuning_directory/\",\n",
    "    project_name=\"eagleeight\"\n",
    ")\n",
    "\n",
    "kwargs = {'epochs': num_epochs,\n",
    "          'verbose': 2,\n",
    "          'shuffle': True\n",
    "         }\n",
    "\n",
    "tuner.search(train_ds, validation_data=val_ds, **kwargs, \\\n",
    "    callbacks=[lr_scheduler, callbacks.EarlyStopping('val_loss', patience=5, restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
